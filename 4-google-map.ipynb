{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5bce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "from parsel import Selector\n",
    "import csv,random, re, os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "INPUT_FILE = \"google_map_queries_new_categories_part_4.csv\"\n",
    "now = datetime.now()\n",
    "formatted_date = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "OUTPUT_FILE = f\"DATA-04-google_map_{formatted_date}.csv\"\n",
    "\n",
    "\n",
    "SKIP_RAW = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "RAW_NUMBER = 0\n",
    "TIMEOUT = 20*1000\n",
    "CDP_WS = \"http://localhost:9223\"\n",
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.connect_over_cdp(CDP_WS)\n",
    "context = browser.contexts[0] if browser.contexts else await browser.new_context()\n",
    "page = await context.new_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404a0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file (with BOM handling)\n",
    "data_rows = []\n",
    "with open(INPUT_FILE, 'r', encoding='utf-8-sig') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    headers = csv_reader.fieldnames\n",
    "    for row in csv_reader:\n",
    "        data_rows.append(row)\n",
    "original_fieldnames = list(data_rows[0].keys()) if data_rows else []\n",
    "new_fieldnames = [\"listing_url\"]\n",
    "all_fieldnames = original_fieldnames + new_fieldnames\n",
    "file_exists = os.path.exists(OUTPUT_FILE)\n",
    "with open(OUTPUT_FILE, 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=all_fieldnames)\n",
    "    writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1894da3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each row and save immediately\n",
    "processed_count = 0\n",
    "for index, row in enumerate(data_rows):\n",
    "    if index < SKIP_RAW:\n",
    "        continue\n",
    "    current_row = index + 1\n",
    "    print(f\"Processing Raw Number: {RAW_NUMBER} ...\")\n",
    "    RAW_NUMBER += 1\n",
    "\n",
    "\n",
    "    \n",
    "    website = (row.get('google_map_search_query') or '').strip()\n",
    "    if not website or 'facebook' in website.lower():\n",
    "        result_row = row.copy()\n",
    "        result_row.update({\n",
    "            \"listing_url\": None,\n",
    "\n",
    "        })\n",
    "\n",
    "        with open(OUTPUT_FILE, 'a', newline='', encoding='utf-8-sig') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=all_fieldnames)\n",
    "            writer.writerow(result_row)\n",
    "\n",
    "        # continue \n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        try:\n",
    "            await page.goto(website, timeout=TIMEOUT)\n",
    "            await page.wait_for_timeout(300)  # brief pause for lazy content\n",
    "        except:\n",
    "            print(\"== Website loaded Error\")\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        END_XPATH = \"//span[contains(., \\\"You've reached the end of the list.\\\")]\"\n",
    "\n",
    "        max_scrolls = 200\n",
    "        stall_limit = 3\n",
    "        stalled = 0\n",
    "        last_count = -1\n",
    "\n",
    "        for i in range(max_scrolls):\n",
    "            await page.evaluate(\"\"\"() => {\n",
    "                const el = document.querySelector('div[role=\"feed\"]');\n",
    "                if (el) el.scrollBy(0, el.scrollHeight);\n",
    "                window.scrollBy(0, 500); // mild nudge for good measure\n",
    "            }\"\"\")\n",
    "            await page.wait_for_timeout(1500)\n",
    "\n",
    "            \n",
    "            html = await page.content()\n",
    "            sel = Selector(text=html)\n",
    "\n",
    "            \n",
    "            if sel.xpath(END_XPATH).get():\n",
    "                print(\"Reached the end of the list banner. Stopping.\")\n",
    "                break\n",
    "\n",
    "\n",
    "            cards = sel.xpath(\"//div[@role='feed']//a[contains(@href,'/maps/place') or contains(@href,'/maps/search')]\").getall()\n",
    "            curr_count = len(cards)\n",
    "            if curr_count == last_count:\n",
    "                stalled += 1\n",
    "                if stalled >= stall_limit:\n",
    "                    print(\"No new results after multiple scrolls. Stopping.\")\n",
    "                    break\n",
    "            else:\n",
    "                stalled = 0\n",
    "                last_count = curr_count\n",
    "\n",
    "            print(f\"Scrolled {i+1}, items seen: {curr_count}\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        await page.wait_for_timeout(500)\n",
    "        html = await page.content()\n",
    "        response = Selector(text=html)\n",
    "\n",
    "\n",
    "        div = response.xpath(\"//a[@class='hfpxzc']\")\n",
    "\n",
    "        for d in div:\n",
    "            listing_url = d.xpath(\"./@href\").get()\n",
    "            \n",
    "\n",
    "            result_row = row.copy()\n",
    "            result_row.update({\n",
    "                \"listing_url\": listing_url,\n",
    "            })\n",
    "            with open(OUTPUT_FILE, 'a', newline='', encoding='utf-8-sig') as csvfile:\n",
    "                writer = csv.DictWriter(csvfile, fieldnames=all_fieldnames)\n",
    "                writer.writerow(result_row)\n",
    "\n",
    "print(f\"\\nProcessing complete! Processed and saved {processed_count} records to {OUTPUT_FILE}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9326fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# await page.goto(\"https://www.google.com/maps/search/restaurant+gastronomique+Paris+1e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83044d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Keep scrolling until the \"end of list\" banner shows up\n",
    "# # and also bail if results stall for a few iterations.\n",
    "# from parsel import Selector\n",
    "\n",
    "# END_XPATH = \"//span[contains(., \\\"You've reached the end of the list.\\\")]\"\n",
    "\n",
    "# max_scrolls = 200          # hard cap (safety)\n",
    "# stall_limit = 3            # how many times in a row we're allowed to see no growth\n",
    "# stalled = 0\n",
    "# last_count = -1\n",
    "\n",
    "# for i in range(max_scrolls):\n",
    "#     # scroll the results panel\n",
    "#     await page.evaluate(\"\"\"() => {\n",
    "#         const el = document.querySelector('div[role=\"feed\"]');\n",
    "#         if (el) el.scrollBy(0, el.scrollHeight);\n",
    "#         window.scrollBy(0, 500); // mild nudge for good measure\n",
    "#     }\"\"\")\n",
    "#     await page.wait_for_timeout(1500)\n",
    "\n",
    "#     # check page state\n",
    "#     html = await page.content()\n",
    "#     sel = Selector(text=html)\n",
    "\n",
    "#     # 1) stop when the end-of-list banner is visible (your XPath idea)\n",
    "#     if sel.xpath(END_XPATH).get():\n",
    "#         print(\"Reached the end of the list banner. Stopping.\")\n",
    "#         break\n",
    "\n",
    "#     # 2) optional: stop if results are no longer increasing\n",
    "#     #    (helps when the banner doesn't appear for some reason)\n",
    "#     cards = sel.xpath(\"//div[@role='feed']//a[contains(@href,'/maps/place') or contains(@href,'/maps/search')]\").getall()\n",
    "#     curr_count = len(cards)\n",
    "#     if curr_count == last_count:\n",
    "#         stalled += 1\n",
    "#         if stalled >= stall_limit:\n",
    "#             print(\"No new results after multiple scrolls. Stopping.\")\n",
    "#             break\n",
    "#     else:\n",
    "#         stalled = 0\n",
    "#         last_count = curr_count\n",
    "\n",
    "#     print(f\"Scrolled {i+1}, items seen: {curr_count}\")\n",
    "\n",
    "# # proceed to parse the final HTML if needed\n",
    "# html = await page.content()\n",
    "# response = Selector(text=html)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd738de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# div = response.xpath(\"//a[@class='hfpxzc']\")\n",
    "\n",
    "# for d in div:\n",
    "#     a = d.xpath(\"./@href\").get()\n",
    "#     print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9128a8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5f1399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# //a[@class='hfpxzc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba7aef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scroll 5 times\n",
    "# for i in range(5):\n",
    "#     print(f\"Scrolling {i+1}/5 ...\")\n",
    "#     await page.evaluate(\"\"\"() => {\n",
    "#         const scrollable = document.querySelector('div[role=\"feed\"]');\n",
    "#         if (scrollable) scrollable.scrollBy(0, scrollable.scrollHeight);\n",
    "#     }\"\"\")\n",
    "#     await page.wait_for_timeout(2000)\n",
    "\n",
    "\n",
    "\n",
    "# html = await page.content()\n",
    "# response = Selector(text = html)\n",
    "\n",
    "\n",
    "# response.xpath(\"//span[contains(text(), 'reached the end of th')]/text()\").get()\n",
    "# # \"You've reached the end of the list.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html = await page.content()\n",
    "# response = Selector(text = html)\n",
    "\n",
    "\n",
    "# response.xpath(\"//span[contains(text(), 'reached the end of th')]/text()\").get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ee8e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
